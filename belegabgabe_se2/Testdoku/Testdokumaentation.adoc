// --- 1. Projektthema -------------------------
= SE II - Testdokumentation: {project-name}
// --- 2. Teammitglieder -----------------------
Michael Novak <s83875@htw-dresden.de>; Magnus Andreas Böhne <s83812@htw-dresden.de>; Manuel Scheer <s83818@htw-dresden.de>; Leon Lowa <s83824@htw-dresden.de>; Jonas Pfeiffer <s83836@htw-dresden.de>
// --- 3. Abgabedatum --------------------------
26. Juni 2022
// ---------------------------------------------
:docs: ../../docs
include::{docs}/_includes/default-attributes.inc.adoc[]

// ---
:doctype: book
:toc:
:toclevels: 2
:toc-title: Inhaltsverzeichnis
:sectnums:
:icons: font
//:source-highlighter: highlightjs
:source-highlighter: rouge
:rouge-style: github
:xrefstyle: full
:experimental:
:chapter-signifier:
:figure-caption: Abbildung
:table-caption: Tabelle
:listing-caption: Listing
:!example-caption:
:experimental:
// Folders
:imagesdir-reset: {imagesdir}
:docs-test2: {docs}/test2
:docs-requirements: {docs}/requirements
:docs-project-management: {docs}/project_management
:docs-architecture: {docs}/architecture
:docs-test: {docs}/test
:docs-development: {docs}/development



include::../_includes/default-attributes.inc.adoc[]
== Testkonzept

=== Testobjekte

Die wichtigsten Komponenten, die getestet wurden, sind das RoboterAPI-Interface und die HomeActivity-Klasse in der Android-Anwendung. Diese Testobjekte wurden mit Unit- und Integrationstests getestet, wobei die Hauptaufmerksamkeit auf der API und der Integration mit der Hauptaktivität lag. Zusätzlich haben wir unseren Testansatz stark auf die jeweiligen Use Cases ausgerichtet. Bei der Implementierung jedes Use Cases erstellten wir einen zugehörigen Testfall, der in der nachfolgenden Iteration ausgeführt wurde.

=== Testmethoden

Wir haben uns für eine Kombination aus Blackbox- und Whitebox-Tests entschieden. Beim Blackbox-Test haben wir die Funktionen der RoboterAPI und HomeActivity ohne Blick auf den internen Code getestet. Beim Whitebox-Test haben wir den internen Code berücksichtigt und Fehler simuliert, wie beispielsweise die API-Fehler, um die Robustheit der App zu überprüfen.

==== Modultests

Nach eingehender Überlegung haben wir beschlossen, Modultests selektiv zu verwenden. Diese Entscheidung basiert auf der Beobachtung, dass einige Module, wie die HomeActivity, im Verlauf des Projekts an Komplexität gewonnen haben. Für diese Module wurden spezifische Modultests erstellt, um deren grundlegende Funktionalität zu gewährleisten. Dazu gehörten automatisierte Tests, die unterschiedliche Aspekte abdeckten. Ein Beispiel dafür ist die Überprüfung des korrekten Verhaltens von RecyclerViews. Mit dieser selektiven Anwendung von Modultests konnten wir sicherstellen, dass die Kernfunktionen unserer komplexeren Module stets ordnungsgemäß funktionieren.

==== Integrationstest

In unserem Testprozess lag ein wesentlicher Schwerpunkt auf Integrationstests. Hierbei orientierten wir uns an den definierten Anwendungsfällen (Use Cases), um die erfolgreiche Zusammenarbeit mehrerer Module sowie deren korrekte Synchronisation zu überprüfen. Besonders berücksichtigt wurde dabei die Zusammenarbeit zwischen der HomeActivity und dem RoboterAPI Service, die eine zentrale Rolle in unserer Anwendung spielt. Auch die Synchronisation mit der Retrofit-Bibliothek und den Datenstrukturen der Entity-Klassen wurden getestet. Diese Integrationstests sind entscheidend, um die korrekte Funktionalität unserer App zu gewährleisten, da sie die Interaktion zwischen den verschiedenen Modulen sicherstellen.

==== Manuelle Tests

Wir als Team haben uns dazu entschieden, aufgrund der überschaubaren Größe des Projekts und der natürlichen Interaktionen, die in einer realen Nutzungssituation auftreten können, eine signifikante Menge an manuellen Tests durchzuführen. Trotz des Wertes automatisierter Tests, waren wir uns bewusst, dass sie nicht alle Aspekte eines komplexen Systems abdecken können, insbesondere in Bezug auf die Benutzerinteraktion und das allgemeine Benutzererlebnis. Die Durchführung von manuellen Tests erlaubte es uns, die App aus der Perspektive des Endbenutzers zu betrachten und dabei subtile Fehler und Verbesserungsmöglichkeiten zu entdecken, die in automatisierten Tests möglicherweise übersehen worden wären. Darüber hinaus war diese Methode angesichts der Größe und Komplexität unseres Projekts sowohl zeit- als auch ressourceneffizient.

=== Akzeptanztest

Im Laufe des Projekts haben wir in regelmäßigen, persönlichen Meetings unsere Fortschritte und einzelnen Systemteile dem Kunden zur Überprüfung präsentiert. Diese iterativen Überprüfungen ermöglichten es uns, wertvolles Feedback in Echtzeit zu erhalten und dieses unmittelbar in unsere Weiterentwicklung einfließen zu lassen. Durch diesen direkten und kontinuierlichen Austausch mit dem Kunden konnten wir sicherstellen, dass unsere Arbeit den Erwartungen und Anforderungen des Kunden entspricht. Aufgrund des zügig erhaltenen Feedbacks konnten wir schnell auf mögliche Anpassungswünsche reagieren und unser System erfolgreich validieren und optimieren.

=== Testdurchführungsplanung

Bei der Testdurchführungsplanung haben wir uns für einen iterativen Ansatz entschieden, der eng mit der Implementierung der einzelnen Use Cases verknüpft war. Für jeden Use Case, der in einer Iteration entwickelt wurde, erstellten wir einen zugehörigen Testfall. Dieser Testfall wurde dann in der darauf folgenden Iteration durchgeführt. Diese Vorgehensweise ermöglichte es uns, Tests direkt mit den Entwicklungsschritten zu verknüpfen und eine kontinuierliche Überprüfung der implementierten Funktionalitäten zu gewährleisten. Dadurch konnten wir sicherstellen, dass jedes neue Feature nicht nur entsprechend den Anforderungen implementiert, sondern auch gründlich getestet und validiert wurde. Dieser Ansatz gewährleistete eine hohe Qualität und Zuverlässigkeit unserer Software, da jede neue Funktion vor ihrer endgültigen Implementierung einer gründlichen Prüfung unterzogen wurde.

== Testen der nicht-funktionalen Anforderungen

===  Systemweite Anforderungen
[cols="4,1,5"]
|===
|Anforderung | Status | Bemerkung

|NFAU-1: Auf Anglizismen sowie technische und informatische Fachbegriffe soll verzichtet werden.
|Teilweise Erfüllt
|ID und FollowMe unter Umständen nicht sofort verständlich

|NFAU-2: Die Anwendung soll ohne technische Kenntnisse des Nutzers bedienbar sein.
|Erfüllt
|-

|NFAU-3: Es ist darauf zu achten, dass die Interaktionsauswahl minimiert wird
|Erfüllt
|-

|NFAU-4: Zur Nutzung der Kernfunktionalität soll die Anwendung mit minimaler Klickzahl steuerbar sein.
|Erfüllt
|-

|NFAU-5: Alle Fehlermeldungen werden dem Nutzer offensichtlich, schnell und verständlich angezeigt.
|Erfüllt
|Verwendung von Android Toasts

|NFAP-1: Innerhalb der App soll das Laden eines Menüs und die Nutzung einer Funktion maximal 3 Sekunden benötigen.
|Erfüllt
|ausgegangen wird dabei von angemessenen Hardwarekomponenten und einer stabilen Internetverbindung


|NFAP-2: Gewählte Aktionen der App sollen innerhalb von 1000 Millisekunden an den Server gesendet, verarbeitet und verifiziert werden.
|Erfüllt
|ausgegangen wird dabei von angemessenen Hardwarekomponenten und einer stabilen Internetverbindung

|NFAP-3: Die Speicherung der Daten auf dem Server soll nicht länger als 5 Sekunden dauern.
|Erfüllt
|-

|NFAP-4: Die Routen sollen möglichst gleich absolviert werden.
|Noch nicht implementiert/Überprüft
|Keine reellen Roboter vorhanden

|NFAP-5: Gesendete Befehle an den Roboter sollen spätestens 6 Sekunden* nach Auswahl ausgeführt werden.
|Noch nicht implementiert/Überprüft
|Keine reellen Roboter vorhanden
|===

[.landscape]

===  Implementierte Use Cases
[cols="4,1,5"]
|===
|Use Case | Status | Bemerkung

|Use Case 01: Roboter anlegen
|Implementiert
|-

|Use Case 02: Roboter bearbeiten
|Teilweise Implementiert
|Wird ein Roboter hinzugefügt, welcher bereits in der Liste steht, wird dieser überschrieben

|Use Case 03: Roboter löschen
|Implementiert
|-

|Use Case 04: Follow-me Funktion starten
|Implementiert
|-

|Use Case 05: Follow-me Funktion ausführen
|Implementiert
|-

|Use Case 06: Follow-me Funktion beenden
|Implementiert
|-


|Use Case 07: Route speichern
|Teilweise Implementiert
|Ansätze in App und Server vorhanden, nicht funktionsfähig

|Use Case 08: Route bearbeiten
|Nicht Implementiert
|-

|Use Case 09: Löschen einer Route
|Teilweise Implementiert
|Funktion ist Serverseitig gegeben

|Use Case 10: Ablaufen einer Route
|Nicht Implementiert
|-

|Use Case 11: Roboter warten
|Nicht Implementiert
|-
|===

[.landscape]
<<<

== Testfallbeschreibung & Testergebnisse

include::../../docs/test/Test_Case_UC01_Roboter_anlegen.adoc[]
<<<
include::../../docs/test/Test_Case_UC02_Roboter_bearbeiten.adoc[]
<<<
include::../../docs/test/Test_Case_UC03_Roboter_löschen.adoc[]
<<<
include::../../docs/test/Test_Case_UC04_Follow_me_Funktion_starten.adoc[]
<<<
include::../../docs/test/Test_Case_UC05_Follow_me_Funktion_ausführen.adoc[]
<<<
include::../../docs/test/Test_Case_UC06_Follow_me_Funktion_beenden.adoc[]
<<<



=== Abnahmetest

Der Abnahmetest ist im https://github.com/SE-I1-Follow-Me/SE-Projekt-I1/blob/main/belegabgabe_se2/abnahmeprotokoll/Abnahmeprotokoll.adoc[Abnahmeprotokoll] aufgeführt.
